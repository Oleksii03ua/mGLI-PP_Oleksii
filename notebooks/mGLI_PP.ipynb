{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13189313",
   "metadata": {},
   "source": [
    "# Multi-Scale Gauss Linking Integral for Protein-Protein Binding Affinity Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b27eb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3378a324",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "print(project_root)\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab0f959",
   "metadata": {},
   "source": [
    "### 1. Processing dataset \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652d0252",
   "metadata": {},
   "source": [
    "#### 1.1 Processing binding affinity labels\n",
    "!!!This section needs to be rewritten since we should convert the various types of binding affinity measure all to  Gibbs free energy. See https://www.nature.com/articles/s42003-023-04866-3 Supplementary Information Supplementary Note 4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10dd82c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_binding_affinity(tsv_file):\n",
    "    \"\"\"\n",
    "    Reads the TSV file and returns two lists:\n",
    "    - pdb_ids: list of PDB IDs\n",
    "    - affinities: list of binding affinity values (ΔG_kJ/mol)\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(tsv_file, sep='\\t')\n",
    "    pdb_ids = df['PDB_ID'].tolist()\n",
    "    affinities = df['ΔG_kJ/mol'].tolist()\n",
    "    return pdb_ids, affinities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c3e5446",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/tmp.dnYnKOa0nW/ipykernel_2546571/742068732.py:16: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  features = torch.load(features_path).numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: mGLI features not found for 6c74\n",
      "Number of samples: 2798\n",
      "Number of features: 1440\n",
      "Number of targets: 2798\n",
      "ΔG range: -89.60 to -3.85 kJ/mol\n"
     ]
    }
   ],
   "source": [
    "# Load features and binding affinity data from TSV\n",
    "dir = \"/home/as4272/protein_design/\"\n",
    "tsv_file = dir + \"topology/mGLI-PP/binding_affinity.tsv\"\n",
    "\n",
    "# Extract PDB IDs and binding affinities from TSV\n",
    "pdb_ids, affinities = extract_binding_affinity(tsv_file)\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# Load mGLI features for each PDB ID that has binding affinity data\n",
    "for i, pdb_id in enumerate(pdb_ids):\n",
    "    try:\n",
    "        # Load mGLI features\n",
    "        features_path = f\"{dir}topology/mGLI-PP/outputs/PDBBind_2020_PP/{pdb_id}_mGLI.pt\"\n",
    "        features = torch.load(features_path).numpy()\n",
    "        \n",
    "        X.append(features)\n",
    "        y.append(affinities[i])  # Use ΔG directly (already in kJ/mol)\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: mGLI features not found for {pdb_id}\")\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading features for {pdb_id}: {e}\")\n",
    "        continue\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Remove samples with NaN in X or y\n",
    "mask = ~(\n",
    "    np.isnan(X).any(axis=1) | np.isnan(y)\n",
    ")\n",
    "X = X[mask]\n",
    "y = y[mask]\n",
    "\n",
    "print(f\"Number of samples: {len(X)}\")\n",
    "print(f\"Number of features: {X.shape[1] if len(X) > 0 else 0}\")\n",
    "print(f\"Number of targets: {len(y)}\")\n",
    "print(f\"ΔG range: {np.min(y):.2f} to {np.max(y):.2f} kJ/mol\")\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3de67d5",
   "metadata": {},
   "source": [
    "#### 1.2 Checking mGLI features\n",
    "Question: why feature.shape is 1440?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09866bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape of each _mGLI.pt file\n",
    "def diagnose_embeddings(emb_dir, labels_tsv):\n",
    "    \"\"\"Diagnostic function to check embedding quality\"\"\"\n",
    "    df = pd.read_csv(labels_tsv, sep=\"\\t\")\n",
    "    pdbs = df[\"PDB_ID\"].tolist()\n",
    "    \n",
    "    for pdb in pdbs[:5]:  # Check first 5\n",
    "        path = os.path.join(emb_dir, f\"{pdb}_mGLI.pt\")\n",
    "        if os.path.exists(path):\n",
    "            emb = torch.load(path)\n",
    "            emb_flat = emb.flatten().numpy()\n",
    "            print(f\"{pdb}: shape={emb.shape}, \"\n",
    "                  f\"flat_shape={emb_flat.shape}, \"\n",
    "                  f\"has_nan={np.isnan(emb_flat).any()}, \"\n",
    "                  f\"has_inf={np.isinf(emb_flat).any()}, \"\n",
    "                  f\"min={emb_flat.min():.3f}, \"\n",
    "                  f\"max={emb_flat.max():.3f}\")\n",
    "        else:\n",
    "            print(f\"{pdb}: File not found\")\n",
    "\n",
    "diagnose_embeddings(project_root+\"/src/features/mGLI\", \n",
    "                   project_root+\"/src/data/data_files/binding_affinity.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec322b40",
   "metadata": {},
   "source": [
    "### 2. Training ML models for prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9acd55",
   "metadata": {},
   "source": [
    "#### 2.1 MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6eab33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MLP regressor...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Train MLP regressor\n",
    "print(\"Training MLP regressor...\")\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(100, 50), activation='relu', max_iter=1000, random_state=42)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Cross-validation on training set\n",
    "print(\"\\nPerforming cross-validation...\")\n",
    "cv_scores_mse = cross_val_score(mlp, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "cv_scores_r2 = cross_val_score(mlp, X_train, y_train, cv=5, scoring='r2')\n",
    "cv_scores_mae = cross_val_score(mlp, X_train, y_train, cv=5, scoring='neg_mean_absolute_error')\n",
    "\n",
    "print(f\"Cross-validation Results (5-fold):\")\n",
    "print(f\"MSE: {-cv_scores_mse.mean():.3f} ± {cv_scores_mse.std():.3f}\")\n",
    "print(f\"MAE: {-cv_scores_mae.mean():.3f} ± {cv_scores_mae.std():.3f}\")\n",
    "print(f\"R²: {cv_scores_r2.mean():.3f} ± {cv_scores_r2.std():.3f}\")\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_train = mlp.predict(X_train)\n",
    "y_pred_test = mlp.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "train_mse = mean_squared_error(y_train, y_pred_train)\n",
    "test_mse = mean_squared_error(y_test, y_pred_test)\n",
    "train_r2 = r2_score(y_train, y_pred_train)\n",
    "test_r2 = r2_score(y_test, y_pred_test)\n",
    "train_mae = mean_absolute_error(y_train, y_pred_train)\n",
    "test_mae = mean_absolute_error(y_test, y_pred_test)\n",
    "\n",
    "print(f\"\\nMLP Performance:\")\n",
    "print(f\"Training - MSE: {train_mse:.3f}, MAE: {train_mae:.3f}, R²: {train_r2:.3f}\")\n",
    "print(f\"Test - MSE: {test_mse:.3f}, MAE: {test_mae:.3f}, R²: {test_r2:.3f}\")\n",
    "\n",
    "# Visualization of model performance\n",
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "# Plot 1: Predictions vs Actual for training set\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.scatter(y_train, y_pred_train, alpha=0.6, color='blue')\n",
    "plt.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual ΔG (kJ/mol)')\n",
    "plt.ylabel('Predicted ΔG (kJ/mol)')\n",
    "plt.title(f'Training Set (R² = {train_r2:.3f})')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Predictions vs Actual for test set\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.scatter(y_test, y_pred_test, alpha=0.6, color='green')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual ΔG (kJ/mol)')\n",
    "plt.ylabel('Predicted ΔG (kJ/mol)')\n",
    "plt.title(f'Test Set (R² = {test_r2:.3f})')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Residuals plot\n",
    "plt.subplot(1, 4, 3)\n",
    "residuals_test = y_test - y_pred_test\n",
    "plt.scatter(y_pred_test, residuals_test, alpha=0.6, color='red')\n",
    "plt.axhline(y=0, color='black', linestyle='--')\n",
    "plt.xlabel('Predicted ΔG (kJ/mol)')\n",
    "plt.ylabel('Residuals (kJ/mol)')\n",
    "plt.title('Residuals Plot (Test Set)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Cross-validation scores\n",
    "plt.subplot(1, 4, 4)\n",
    "x_pos = [1, 2, 3]\n",
    "scores = [-cv_scores_mse.mean(), -cv_scores_mae.mean(), cv_scores_r2.mean()]\n",
    "errors = [cv_scores_mse.std(), cv_scores_mae.std(), cv_scores_r2.std()]\n",
    "labels = ['MSE', 'MAE', 'R²']\n",
    "plt.bar(x_pos, scores, yerr=errors, capsize=5, alpha=0.7)\n",
    "plt.xticks(x_pos, labels)\n",
    "plt.ylabel('Score')\n",
    "plt.title('Cross-validation Scores (±1 std)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Hyperparameter tuning with cross-validation\n",
    "print(\"\\nPerforming hyperparameter tuning...\")\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (100, 50), (200, 100), (100, 50, 25)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'learning_rate_init': [0.001, 0.01]\n",
    "}\n",
    "\n",
    "mlp_grid = MLPRegressor(max_iter=1000, random_state=42)\n",
    "grid = GridSearchCV(mlp_grid, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best parameters: {grid.best_params_}\")\n",
    "print(f\"Best CV score (MSE): {-grid.best_score_:.3f}\")\n",
    "\n",
    "# Evaluate best model\n",
    "best_mlp = grid.best_estimator_\n",
    "y_pred_best = best_mlp.predict(X_test)\n",
    "best_r2 = r2_score(y_test, y_pred_best)\n",
    "best_mse = mean_squared_error(y_test, y_pred_best)\n",
    "best_mae = mean_absolute_error(y_test, y_pred_best)\n",
    "\n",
    "print(f\"\\nBest MLP Performance on Test Set:\")\n",
    "print(f\"MSE: {best_mse:.3f}, MAE: {best_mae:.3f}, R²: {best_r2:.3f}\")\n",
    "\n",
    "# Cross-validation on best model\n",
    "best_cv_scores_mse = cross_val_score(best_mlp, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "best_cv_scores_r2 = cross_val_score(best_mlp, X_train, y_train, cv=5, scoring='r2')\n",
    "best_cv_scores_mae = cross_val_score(best_mlp, X_train, y_train, cv=5, scoring='neg_mean_absolute_error')\n",
    "\n",
    "print(f\"\\nBest Model Cross-validation Results (5-fold):\")\n",
    "print(f\"MSE: {-best_cv_scores_mse.mean():.3f} ± {best_cv_scores_mse.std():.3f}\")\n",
    "print(f\"MAE: {-best_cv_scores_mae.mean():.3f} ± {best_cv_scores_mae.std():.3f}\")\n",
    "print(f\"R²: {best_cv_scores_r2.mean():.3f} ± {best_cv_scores_r2.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96a7878",
   "metadata": {},
   "source": [
    "#### 2.2 Random forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74214606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be added"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4939a2",
   "metadata": {},
   "source": [
    "#### 2.3 Gradient boost decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d864c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be added"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "protein_design",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
